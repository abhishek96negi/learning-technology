{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6834946a",
   "metadata": {},
   "source": [
    "Celery is a simple, flexible, and reliable distributed system to process vast amounts of messages, while providing operations with the tools required to maintain such a system.\n",
    "\n",
    "It's a task queue with focus on real-time processing, while also supporting task scheduling.\n",
    "\n",
    "Task queues are used as a mechanism to distribute work across threads or machines.\n",
    "\n",
    "A Celery system can consist of multiple workers and brokers, giving way to high availability and horizontal scaling.\n",
    "\n",
    "Celery allows you to execute background tasks asynchronously, which is especially useful for long-running or time-consuming operations that shouldn't block the main application.\n",
    "\n",
    "Celery is written in Python, but the protocol can be implemented in any language.\n",
    "\n",
    "Celery can run on a single machine, on multiple machines, or even across data centre."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8111de",
   "metadata": {},
   "source": [
    "## Request Response without Celery\n",
    "\n",
    "![celery1](../image/celery/celery1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c792318d",
   "metadata": {},
   "source": [
    "## How Celery works\n",
    "\n",
    "![celery2](../image/celery/celery2.png)\n",
    "\n",
    "* User Sends a Request to and Application which may be on a Server.\n",
    "\n",
    "* Application server handles the request, If there is time-consuming task then task will be enqueue to message broker.\n",
    "\n",
    "* If required return the reponse to User so user won't have to wait for completion of task. User can use application further and send another request.\n",
    "\n",
    "* In the backgorund, Celery worker continuously monitor task queue, when it finds a new task it starts to process it. The worker runs the task code asynchronously, independent of the user's request-response cycle.\n",
    "\n",
    "* The celery worker executes the task code, performing the required computation or operation.\n",
    "\n",
    "* Once the task is completed, it produces a result (if any) and stores it somewhere, as in the result backend (like Redis or a database)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d6fb32",
   "metadata": {},
   "source": [
    "## Response after Task Result\n",
    "\n",
    "* If the task result is needed at a later point or if the user makes a separate request to check the status or result of the task, the application can retrieve the task result from the result backend using Celery's API.\n",
    "\n",
    "* If the task result wasn't immediately available when the user made the initial request, and the application decided to send a response without waiting for the task, the user might make subsequent requests to fetch the result. The final response, containing the task result, is sent to the user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6510a13f",
   "metadata": {},
   "source": [
    "## Message Broker\n",
    "\n",
    "* In Celery, a message broker is a crucial component that acts as an intermediary between the Celery client (the application that sends tasks) and the Celery workers (the processes that execute the tasks).\n",
    "\n",
    "* It facilitates communication by passing messages containing task information from the client to the workets.\n",
    "\n",
    "* When a task is enqueued in Celery, the message broker receives the task message and stores it in a queue.\n",
    "\n",
    "* The primary functions of a message broker in Celery are Message Queueing, Task Distribution and Commuincation Channel.\n",
    "\n",
    "* Popular Message Brokers supported by Celery are RabbitMQ, Redis and Amazon Simple Queue Service(SQS)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3db315a",
   "metadata": {},
   "source": [
    "## Celery Worker\n",
    "\n",
    "* In celery, a worker is a process that performs the actual execution of tasks.\n",
    "\n",
    "* It is one of the core components of the Celery distributed task queue system.\n",
    "\n",
    "* When you enqueue a task in Celery, it is sent to the worker processes, where the task is executed asynchronously in the background.\n",
    "\n",
    "* Functionalities of Celery workers are Task Execution, Concurrency, Dynamic Scaling, Task Acknowledgement, Result Handling, task Priority and Error Reporting.\n",
    "\n",
    "* When you start a Celery worker process, it continuously listens to the message broker for incoming tasks. As soon as a task is enqueued in the message queue, the worker picks up the task and executes it. The process is repeated as long as the worker is running.\n",
    "\n",
    "* `celery -A project_name worker -l INFO` - It is used to start worker process for testing and development."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfba345",
   "metadata": {},
   "source": [
    "## Celery Worker Process\n",
    "\n",
    "* A worker process, in the context of Celery, refers to and independent and concurrent process that executes tasks asynchronously.\n",
    "\n",
    "* When you start a Celery worker, it creates one or more worker processes to handle incoming tasks from the message broker.\n",
    "\n",
    "* Each worker process operates independently and can execute tasks concurrently with other worker processes.\n",
    "\n",
    "* These worker processes are responsible for processing the tasks that are enqueued in the Celery message queue by the Celery client (your application) and the Celery Beat scheduler.\n",
    "\n",
    "* By carefully managing worker processes and their concurrency, you can optimize the performance and resource utilization of your Celery application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2508fff9",
   "metadata": {},
   "source": [
    "## Determine Number of Process/ Concurrency\n",
    "\n",
    "* The number of processes a Celery worker can have depends on your system's resources and how you configure the worker.\n",
    "\n",
    "* It is usually recommended to set the concurrency level equal to or slightly lower than the number of CPU cores.\n",
    "\n",
    "* In some situations, you might want to have more worker processes than CPU cores, especially when your tasks are primarily I/O-bound tasks (e.g., making API calls, accessing databases, reading/writing files). It is also an area where you can utilize thread pool.\n",
    "\n",
    "* In situations where your tasks are predominantly CPU-bound (e.g., heavy computations, complex algorithms), it is generally more meaningful to have equal or fewer worker processes than the number of CPU cores. It is also an area where you can utilize multi process pool.\n",
    "\n",
    "* `celery -A project-name worker -l INFO --concurrecny=6`\n",
    "\n",
    "* The --concurrency option allows you to specify the number of worker processes or threads that should run concurrently to process tasks.\n",
    "\n",
    "* It sets the level of concurrency for the Celery worker.\n",
    "\n",
    "* If you use the --concurrency option without specifying a --pool, Celery will use the default Prefork pool."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
