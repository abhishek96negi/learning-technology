{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6834946a",
   "metadata": {},
   "source": [
    "Celery is a simple, flexible, and reliable distributed system to process vast amounts of messages, while providing operations with the tools required to maintain such a system.\n",
    "\n",
    "It's a task queue with focus on real-time processing, while also supporting task scheduling.\n",
    "\n",
    "Task queues are used as a mechanism to distribute work across threads or machines.\n",
    "\n",
    "A Celery system can consist of multiple workers and brokers, giving way to high availability and horizontal scaling.\n",
    "\n",
    "Celery allows you to execute background tasks asynchronously, which is especially useful for long-running or time-consuming operations that shouldn't block the main application.\n",
    "\n",
    "Celery is written in Python, but the protocol can be implemented in any language.\n",
    "\n",
    "Celery can run on a single machine, on multiple machines, or even across data centre."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8111de",
   "metadata": {},
   "source": [
    "## Request Response without Celery\n",
    "\n",
    "![celery1](../image/celery/celery1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c792318d",
   "metadata": {},
   "source": [
    "## How Celery works\n",
    "\n",
    "![celery2](../image/celery/celery2.png)\n",
    "\n",
    "* User Sends a Request to and Application which may be on a Server.\n",
    "\n",
    "* Application server handles the request, If there is time-consuming task then task will be enqueue to message broker.\n",
    "\n",
    "* If required return the reponse to User so user won't have to wait for completion of task. User can use application further and send another request.\n",
    "\n",
    "* In the backgorund, Celery worker continuously monitor task queue, when it finds a new task it starts to process it. The worker runs the task code asynchronously, independent of the user's request-response cycle.\n",
    "\n",
    "* The celery worker executes the task code, performing the required computation or operation.\n",
    "\n",
    "* Once the task is completed, it produces a result (if any) and stores it somewhere, as in the result backend (like Redis or a database)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d6fb32",
   "metadata": {},
   "source": [
    "## Response after Task Result\n",
    "\n",
    "* If the task result is needed at a later point or if the user makes a separate request to check the status or result of the task, the application can retrieve the task result from the result backend using Celery's API.\n",
    "\n",
    "* If the task result wasn't immediately available when the user made the initial request, and the application decided to send a response without waiting for the task, the user might make subsequent requests to fetch the result. The final response, containing the task result, is sent to the user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6510a13f",
   "metadata": {},
   "source": [
    "## Message Broker\n",
    "\n",
    "* In Celery, a message broker is a crucial component that acts as an intermediary between the Celery client (the application that sends tasks) and the Celery workers (the processes that execute the tasks).\n",
    "\n",
    "* It facilitates communication by passing messages containing task information from the client to the workets.\n",
    "\n",
    "* When a task is enqueued in Celery, the message broker receives the task message and stores it in a queue.\n",
    "\n",
    "* The primary functions of a message broker in Celery are Message Queueing, Task Distribution and Commuincation Channel.\n",
    "\n",
    "* Popular Message Brokers supported by Celery are RabbitMQ, Redis and Amazon Simple Queue Service(SQS)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3db315a",
   "metadata": {},
   "source": [
    "## Celery Worker\n",
    "\n",
    "* In celery, a worker is a process that performs the actual execution of tasks.\n",
    "\n",
    "* It is one of the core components of the Celery distributed task queue system.\n",
    "\n",
    "* When you enqueue a task in Celery, it is sent to the worker processes, where the task is executed asynchronously in the background.\n",
    "\n",
    "* Functionalities of Celery workers are Task Execution, Concurrency, Dynamic Scaling, Task Acknowledgement, Result Handling, task Priority and Error Reporting.\n",
    "\n",
    "* When you start a Celery worker process, it continuously listens to the message broker for incoming tasks. As soon as a task is enqueued in the message queue, the worker picks up the task and executes it. The process is repeated as long as the worker is running.\n",
    "\n",
    "* `celery -A project_name worker -l INFO` - It is used to start worker process for testing and development."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfba345",
   "metadata": {},
   "source": [
    "## Celery Worker Process\n",
    "\n",
    "* A worker process, in the context of Celery, refers to and independent and concurrent process that executes tasks asynchronously.\n",
    "\n",
    "* When you start a Celery worker, it creates one or more worker processes to handle incoming tasks from the message broker.\n",
    "\n",
    "* Each worker process operates independently and can execute tasks concurrently with other worker processes.\n",
    "\n",
    "* These worker processes are responsible for processing the tasks that are enqueued in the Celery message queue by the Celery client (your application) and the Celery Beat scheduler.\n",
    "\n",
    "* By carefully managing worker processes and their concurrency, you can optimize the performance and resource utilization of your Celery application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2508fff9",
   "metadata": {},
   "source": [
    "## Determine Number of Process/ Concurrency\n",
    "\n",
    "* The number of processes a Celery worker can have depends on your system's resources and how you configure the worker.\n",
    "\n",
    "* It is usually recommended to set the concurrency level equal to or slightly lower than the number of CPU cores.\n",
    "\n",
    "* In some situations, you might want to have more worker processes than CPU cores, especially when your tasks are primarily I/O-bound tasks (e.g., making API calls, accessing databases, reading/writing files). It is also an area where you can utilize thread pool.\n",
    "\n",
    "* In situations where your tasks are predominantly CPU-bound (e.g., heavy computations, complex algorithms), it is generally more meaningful to have equal or fewer worker processes than the number of CPU cores. It is also an area where you can utilize multi process pool.\n",
    "\n",
    "* `celery -A project-name worker -l INFO --concurrecny=6`\n",
    "\n",
    "* The --concurrency option allows you to specify the number of worker processes or threads that should run concurrently to process tasks.\n",
    "\n",
    "* It sets the level of concurrency for the Celery worker.\n",
    "\n",
    "* If you use the --concurrency option without specifying a --pool, Celery will use the default Prefork pool."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96417c66",
   "metadata": {},
   "source": [
    "## What is Pool\n",
    "\n",
    "* In Celery, a pool is a mechanism used to manage the execution of tasks by controlling the number of worker processes available for task processing.\n",
    "\n",
    "* It allows you to specify how concurrent task execution should be managed and how worker processes are allocated and utilized.\n",
    "\n",
    "* The pool can be configured to optimize the performance and resource utlization of the Celery worker.\n",
    "\n",
    "* Some common pool implementations in Celery are prefork, threads, solo, gevent, eventlet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a46fd3",
   "metadata": {},
   "source": [
    "### Pools\n",
    "\n",
    "* **Prefork** :- The Prefork is the default pool in Celery. It precreates a fixed number of worker processes when the Celery worker starts, and each worker process can handle one task at a time. Tasks are distributed to available worker processes in round-robin fashion.\n",
    "\n",
    "* **Thread** :- The Threads uses threads instead of separate processes for concurrency. It is suitable for I/O-bound tasks where threads can be more efficient than separate processes. Each worker thread can handle one task at a time.\n",
    "\n",
    "* **Solo** :- The Solo is a special pool that runs a single worker process without any concurrency. It is useful when you want to limit task execution to one task at a time making it easier to ensure that tasks are executed sequentially.\n",
    "\n",
    "* **Gevent** :- The Gevent is an asynchronous pool that uses greenlets from the Gevent library for concurrency. It is a good option for applications that heavily rely on I/O operations. Greenlets are lighter than threads or processes and are suitable for I/O-bound tasks.\n",
    "\n",
    "* **Eventlet** :- Similar to the Gevent, the Eventlet uses greenlets from the Eventlet library for concurrency. It offers similar benefits for I/O-bound tasks.\n",
    "\n",
    "* `celery -A project_name worker -l INFO --pool=gevent`\n",
    "\n",
    "* The --pool option allows you to explicitly specify the type of pool to use for concurrency.\n",
    "\n",
    "* The pool determines how worker processes or threads are managed and how tasks are distributed among them.\n",
    "\n",
    "* If you use the --pool option, it overridees the default Prefork pool selection, and Celery will use the specified pool implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a770cfc",
   "metadata": {},
   "source": [
    "## Celery Use Cases\n",
    "\n",
    "* Asynchronous Task Processing\n",
    "* Long-Running API Calls\n",
    "* File Processing and Uploads\n",
    "* Data Scarping and Web Crawling\n",
    "* Distributed and Parallel Processing\n",
    "* Machine Learning and Data Analysis\n",
    "* Real-Time Notifications and Updates\n",
    "* Integration with External Services\n",
    "* Periodic Task Execution"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
